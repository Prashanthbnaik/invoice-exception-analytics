{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881ca775-715d-48c3-8660-99efdbe4934a",
   "metadata": {},
   "source": [
    "# 02 - Data Cleaning and Preprocessing\n",
    "\n",
    "## Notebook Objective:\n",
    "\n",
    "This notebook focuses on cleaning and preprocessing the raw, messy `mock_dataset.csv` identified in `01_data_loading_and_initial_inspection.ipynb`. We will systematically address various data quality issues to prepare a clean, reliable dataset for subsequent analysis.\n",
    "\n",
    "The key cleaning steps will include:\n",
    "1.  Initial Column Management (renaming, dropping redundant columns)\n",
    "2.  Handling Duplicate Rows\n",
    "3.  Standardizing Column Names\n",
    "4.  Correcting Data Types (Dates, Numerics)\n",
    "5.  Addressing Missing Values\n",
    "6.  Handling Inconsistent Text Formats (Whitespace, Casing)\n",
    "7.  Dealing with Invalid Data and Outliers\n",
    "8.  Final Data Validation\n",
    "\n",
    "Our goal is to transform the `mock_dataset.csv` into a `cleaned_data.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d3a0a-2238-4422-b93c-d45ac852fffb",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c734ec51-1af1-44ce-9f34-4e34a2add527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0955b337-98bf-45e4-afdd-a90a9955c21e",
   "metadata": {},
   "source": [
    "Define File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d7fdf8-d4d2-48fc-a5cc-6492e3d6052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Prashanth\\OneDrive\\ドキュメント\\Portfolio_Projects_DA\\Consolidated Invoicing, Engine, and Exception Analytics\\data\\mock_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d2011-24a5-4eb8-8a23-4b9a57024a8f",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4c49bc-4425-4f67-8bb7-93f5fb295683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded successfully for cleaning.\n",
      "Initial rows: 10113\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"dataset loaded successfully for cleaning.\")\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{messy_file_path}' was not found.\")\n",
    "    df = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcabd27-88cd-4b98-85b0-4a35ed846726",
   "metadata": {},
   "source": [
    "### 1. Initial Column Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca3def8-0cad-4b53-9e24-864b9258f7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Columns before management ---\n",
      "['Count of Invoice', 'Type of Request', 'REQUEST ID', 'CREATED BY', 'CREATED ON', 'BRANCH NAME', 'SUPPLIER CODE', 'NAME', 'COUNTRY', 'CURRENCY', 'TYPE OF REQUEST', 'Amount', 'TASK START', 'Actioned Date', 'Request Received Stage', 'Request received date', 'Completed Date', 'Status of Request', 'Pending Reason', 'Pending With Approver/Requestor', 'QC Status', 'Audited By', 'Auditor Comments', 'Ageing-SLA-FPY', 'Ageing-SLA-2', 'Ageing of Re-work Days', 'Ageing of Re-work', 'Month', 'Unnamed: 28', ' Amount ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Columns before management ---\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff6556-796d-44b3-a759-bc4bbaefce11",
   "metadata": {},
   "source": [
    "Drop the entirely empty and redundant ' Amount ' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b760bce1-b2d0-416f-8666-ea63d7dd986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped redundant column: ' Amount '.\n"
     ]
    }
   ],
   "source": [
    "if ' Amount ' in df.columns: # Check if the column with space exists\n",
    "    df.drop(columns=[' Amount '], inplace=True)\n",
    "    print(f\"\\nDropped redundant column: ' Amount '.\")\n",
    "else:\n",
    "    print(f\"\\nRedundant column ' Amount ' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd25849a-cf42-438a-9866-d4dc06b2da5c",
   "metadata": {},
   "source": [
    "columns after Initial Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9abb9e04-ba77-4fda-9255-e65d79774193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Columns after initial management ---\n",
      "['Count of Invoice', 'Type of Request', 'REQUEST ID', 'CREATED BY', 'CREATED ON', 'BRANCH NAME', 'SUPPLIER CODE', 'NAME', 'COUNTRY', 'CURRENCY', 'TYPE OF REQUEST', 'Amount', 'TASK START', 'Actioned Date', 'Request Received Stage', 'Request received date', 'Completed Date', 'Status of Request', 'Pending Reason', 'Pending With Approver/Requestor', 'QC Status', 'Audited By', 'Auditor Comments', 'Ageing-SLA-FPY', 'Ageing-SLA-2', 'Ageing of Re-work Days', 'Ageing of Re-work', 'Month', 'Unnamed: 28']\n",
      "\n",
      "DataFrame shape after initial column management: (10113, 29)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Columns after initial management ---\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(f\"\\nDataFrame shape after initial column management: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b149b84-0728-4726-ab58-d6d45bebd1a5",
   "metadata": {},
   "source": [
    "### 2. Drop Entirely Empty/Redundant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990ce80-1f89-4e18-bd17-dbfce2b2c47c",
   "metadata": {},
   "source": [
    "These columns were identified in initial inspection (01_data_loading_and_initial_inspection.ipynb)\n",
    "as having 0 non-null values, providing no useful information for this analysis project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826fb7a5-3479-44aa-acba-095493336ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_due_to_emptiness = [\n",
    "    'Ageing-SLA-2',\n",
    "    'Ageing of Re-work Days',\n",
    "    'Ageing of Re-work',\n",
    "    'Unnamed: 28'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26817ea8-a8d4-46a5-8dc6-85cb844e0894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ageing-SLA-2', 'Ageing of Re-work Days', 'Ageing of Re-work', 'Unnamed: 28']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if Column exist before attempting to drop\n",
    "existing_columns_to_drop = [col for col in columns_to_drop_due_to_emptiness if col in df.columns]\n",
    "existing_columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16717f32-55f2-4ce8-94f0-0c114f769e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped  empty columns: ['Ageing-SLA-2', 'Ageing of Re-work Days', 'Ageing of Re-work', 'Unnamed: 28']\n"
     ]
    }
   ],
   "source": [
    "if existing_columns_to_drop:\n",
    "    df.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "    print(f\"\\nDropped  empty columns: {existing_columns_to_drop}\")\n",
    "else:\n",
    "    print(\"\\nNo additional empty columns found to drop.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc6a090-648c-4c7e-b853-bc5aecbbc764",
   "metadata": {},
   "source": [
    "Current Columns after dropping empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0e8aba-4299-4eca-a1b3-5abe08df5e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame shape after dropping empty columns: (10113, 25)\n",
      "\n",
      "Current Columns after dropping empty ones ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Count of Invoice',\n",
       " 'Type of Request',\n",
       " 'REQUEST ID',\n",
       " 'CREATED BY',\n",
       " 'CREATED ON',\n",
       " 'BRANCH NAME',\n",
       " 'SUPPLIER CODE',\n",
       " 'NAME',\n",
       " 'COUNTRY',\n",
       " 'CURRENCY',\n",
       " 'TYPE OF REQUEST',\n",
       " 'Amount',\n",
       " 'TASK START',\n",
       " 'Actioned Date',\n",
       " 'Request Received Stage',\n",
       " 'Request received date',\n",
       " 'Completed Date',\n",
       " 'Status of Request',\n",
       " 'Pending Reason',\n",
       " 'Pending With Approver/Requestor',\n",
       " 'QC Status',\n",
       " 'Audited By',\n",
       " 'Auditor Comments',\n",
       " 'Ageing-SLA-FPY',\n",
       " 'Month']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\nDataFrame shape after dropping empty columns: {df.shape}\")\n",
    "print(\"\\nCurrent Columns after dropping empty ones ---\")\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792250f5-759a-4e45-b1f4-72dfc7c9ccbb",
   "metadata": {},
   "source": [
    "### 3. Handle Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94fe08f6-c407-4c25-b000-6ffd58d4e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows before dropping duplicates: 10113\n",
      "Rows after dropping exact duplicates: 10013\n",
      "Number of duplicate rows removed: 100\n"
     ]
    }
   ],
   "source": [
    "initial_rows = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"\\nRows before dropping duplicates: {initial_rows}\")\n",
    "print(f\"Rows after dropping exact duplicates: {len(df)}\")\n",
    "print(f\"Number of duplicate rows removed: {initial_rows - len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4512e2-70ea-4756-8184-6233ab72e012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame shape after handling duplicates: (10013, 25)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nDataFrame shape after handling duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ada1ed-194f-4e69-895b-64db29431094",
   "metadata": {},
   "source": [
    "### 4. Standardize Column Names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90bce8-6f36-4ac0-b52e-2b39e1da9265",
   "metadata": {},
   "source": [
    "Strip whitespace and replace spaces/hyphens with underscores, then convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daa79589-c25b-48fe-adc6-54c3279a2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('-', '_').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d57da-8b8e-46cd-9b7b-2e3735b9bc75",
   "metadata": {},
   "source": [
    "Handle any double underscores that might result from multiple replacements (e.g., 'TYPE__OF__REQUEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eefa834-e26e-4dc8-89fd-cc9d987e401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('__', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea904d5-f8be-4ddf-bbd8-a26fa0588930",
   "metadata": {},
   "source": [
    "Remove any trailing underscores if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b49f05d-722e-42b9-b7e4-3ac01e963f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.rstrip('_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb0f6b-8c9f-4887-992b-58970bb60b70",
   "metadata": {},
   "source": [
    "Column names after standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6c42a77-5f9e-4f43-aa3d-c0814c558cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame shape after standardizing column names: (10013, 25)\n",
      "\n",
      "Column names after standardization ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['count_of_invoice',\n",
       " 'type_of_request',\n",
       " 'request_id',\n",
       " 'created_by',\n",
       " 'created_on',\n",
       " 'branch_name',\n",
       " 'supplier_code',\n",
       " 'name',\n",
       " 'country',\n",
       " 'currency',\n",
       " 'type_of_request',\n",
       " 'amount',\n",
       " 'task_start',\n",
       " 'actioned_date',\n",
       " 'request_received_stage',\n",
       " 'request_received_date',\n",
       " 'completed_date',\n",
       " 'status_of_request',\n",
       " 'pending_reason',\n",
       " 'pending_with_approver/requestor',\n",
       " 'qc_status',\n",
       " 'audited_by',\n",
       " 'auditor_comments',\n",
       " 'ageing_sla_fpy',\n",
       " 'month']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\nDataFrame shape after standardizing column names: {df.shape}\")\n",
    "\n",
    "print(\"\\nColumn names after standardization ---\")\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00449471-3ba6-4914-8492-52ef00ced555",
   "metadata": {},
   "source": [
    "### 5. Correct Data Types(Dates & Numerics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d2c90-6e10-4204-9157-dc83fe0d3cec",
   "metadata": {},
   "source": [
    "Convert Date Columns to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "348d189c-61db-49c2-9a1b-6483f0d2b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converted Date Columns to Datetime Objects ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConverted Date Columns to Datetime Objects ---\")\n",
    "\n",
    "df['created_on'] = pd.to_datetime(df['created_on'], errors='coerce')\n",
    "df['task_start'] = pd.to_datetime(df['task_start'], errors='coerce')\n",
    "df['actioned_date'] = pd.to_datetime(df['actioned_date'], errors='coerce')\n",
    "df['request_received_date'] = pd.to_datetime(df['request_received_date'], errors='coerce')\n",
    "df['completed_date'] = pd.to_datetime(df['completed_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf56e82-e095-48d3-8008-082d8bd697d8",
   "metadata": {},
   "source": [
    " Convert 'amount' to Numeric (float) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64132b40-6c15-4950-9819-71450204291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 'amount' converted to float.\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'amount' column to Numeric.\n",
    "if 'amount' in df.columns:\n",
    "    df['amount'] = pd.to_numeric(df['amount'], errors='coerce')\n",
    "    print(f\"  - 'amount' converted to float.\")\n",
    "else:\n",
    "    print(f\"  - WARNING: 'amount' column not found. Skipping conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe95f4-9cbe-40c0-b86d-868e11d7189f",
   "metadata": {},
   "source": [
    "Check data types after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "835fd5ad-7953-4b27-82e9-9f13e1f343a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types After Date Conversions ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10013 entries, 0 to 10012\n",
      "Data columns (total 25 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   count_of_invoice                 10010 non-null  float64       \n",
      " 1   type_of_request                  10013 non-null  object        \n",
      " 2   request_id                       10013 non-null  int64         \n",
      " 3   created_by                       10013 non-null  object        \n",
      " 4   created_on                       10011 non-null  datetime64[ns]\n",
      " 5   branch_name                      10013 non-null  object        \n",
      " 6   supplier_code                    10013 non-null  object        \n",
      " 7   name                             10013 non-null  object        \n",
      " 8   country                          10013 non-null  object        \n",
      " 9   currency                         10013 non-null  object        \n",
      " 10  type_of_request                  10013 non-null  object        \n",
      " 11  amount                           10002 non-null  float64       \n",
      " 12  task_start                       10013 non-null  datetime64[ns]\n",
      " 13  actioned_date                    10013 non-null  datetime64[ns]\n",
      " 14  request_received_stage           9712 non-null   object        \n",
      " 15  request_received_date            10013 non-null  datetime64[ns]\n",
      " 16  completed_date                   9944 non-null   datetime64[ns]\n",
      " 17  status_of_request                9959 non-null   object        \n",
      " 18  pending_reason                   1817 non-null   object        \n",
      " 19  pending_with_approver/requestor  1193 non-null   object        \n",
      " 20  qc_status                        8828 non-null   object        \n",
      " 21  audited_by                       3870 non-null   object        \n",
      " 22  auditor_comments                 3874 non-null   object        \n",
      " 23  ageing_sla_fpy                   9683 non-null   float64       \n",
      " 24  month                            9819 non-null   object        \n",
      "dtypes: datetime64[ns](5), float64(3), int64(1), object(16)\n",
      "memory usage: 2.0+ MB\n",
      "\n",
      "DataFrame shape after date conversions: (10013, 25)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Types After Date Conversions ---\")\n",
    "df.info() # This will show all data types, including newly converted date columns.\n",
    "\n",
    "print(f\"\\nDataFrame shape after date conversions: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6965fc-6316-497c-9c1b-626029762a82",
   "metadata": {},
   "source": [
    "### 6. Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8005645-9e4b-40c6-b034-c4bebaa123ab",
   "metadata": {},
   "source": [
    "Impute Missing 'created_on' Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17d907-0246-4d15-a2b7-0778790cea2c",
   "metadata": {},
   "source": [
    "Filling with the mode (most frequent date) is a common strategy for date imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8fe438e-eb94-4a3c-b954-652746d778c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Imputed 2 missing 'created_on' values with the mode: 2025-04-10.\n"
     ]
    }
   ],
   "source": [
    "# Impute Missing 'created_on' Dates ---\n",
    "\n",
    "if 'created_on' in df.columns:\n",
    "    missing_count_before = df['created_on'].isnull().sum()\n",
    "    if missing_count_before > 0:\n",
    "        mode_created_on = df['created_on'].mode()[0]\n",
    "        df['created_on'] = df['created_on'].fillna(mode_created_on) \n",
    "        print(f\"  - Imputed {missing_count_before} missing 'created_on' values with the mode: {mode_created_on.strftime('%Y-%m-%d')}.\")\n",
    "    else:\n",
    "        print(\"  - No missing 'created_on' dates to impute.\")\n",
    "else:\n",
    "    print(\"  - WARNING: 'created_on' column not found. Skipping imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d959b3-b08b-47d9-ae3f-5c4eb9c18d21",
   "metadata": {},
   "source": [
    "Handle Missing Categorical/Text Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6b1e4-1c87-43f7-8843-5c07d1aa135a",
   "metadata": {},
   "source": [
    "Filling missing values in descriptive columns with 'Unknown' or 'Not Applicable'\n",
    "ensures these records remain usable and their missingness is explicitly noted for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb1978b-3343-430c-81e9-bf09c75650b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns and their respective fill values\n",
    "columns_to_fill_with_string = {\n",
    "    'request_received_stage': 'Unknown Stage',\n",
    "    'status_of_request': 'Unknown Status',\n",
    "    'pending_reason': 'No Pending Reason',\n",
    "    'pending_with_approver/requestor': 'No Pending Party',\n",
    "    'qc_status': 'Not Reviewed',\n",
    "    'audited_by': 'Not Applicable',\n",
    "    'auditor_comments': 'No Comments'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adfc13f2-dcf4-4ee5-9022-979757cbaf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Filling Missing Categorical/Text Values ---\n",
      "  - Filled 301 missing values in 'request_received_stage' with 'Unknown Stage'.\n",
      "  - Filled 54 missing values in 'status_of_request' with 'Unknown Status'.\n",
      "  - Filled 8196 missing values in 'pending_reason' with 'No Pending Reason'.\n",
      "  - Filled 8820 missing values in 'pending_with_approver/requestor' with 'No Pending Party'.\n",
      "  - Filled 1185 missing values in 'qc_status' with 'Not Reviewed'.\n",
      "  - Filled 6143 missing values in 'audited_by' with 'Not Applicable'.\n",
      "  - Filled 6139 missing values in 'auditor_comments' with 'No Comments'.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Filling Missing Categorical/Text Values ---\")\n",
    "for col, fill_value in columns_to_fill_with_string.items():\n",
    "    if col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        \n",
    "        if missing_count > 0:\n",
    "            df[col] = df[col].fillna(fill_value) \n",
    "            print(f\"  - Filled {missing_count} missing values in '{col}' with '{fill_value}'.\")\n",
    "        else:\n",
    "            print(f\"  - No missing values found in '{col}'.\")\n",
    "    else:\n",
    "        print(f\"  - WARNING: Column '{col}' not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bfbb82a-a2b6-427d-853a-5f9c3d1e4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Missing Values after all specified handling ---\n",
      "count_of_invoice                     3\n",
      "type_of_request                      0\n",
      "request_id                           0\n",
      "created_by                           0\n",
      "created_on                           0\n",
      "branch_name                          0\n",
      "supplier_code                        0\n",
      "name                                 0\n",
      "country                              0\n",
      "currency                             0\n",
      "type_of_request                      0\n",
      "amount                              11\n",
      "task_start                           0\n",
      "actioned_date                        0\n",
      "request_received_stage               0\n",
      "request_received_date                0\n",
      "completed_date                      69\n",
      "status_of_request                    0\n",
      "pending_reason                       0\n",
      "pending_with_approver/requestor      0\n",
      "qc_status                            0\n",
      "audited_by                           0\n",
      "auditor_comments                     0\n",
      "ageing_sla_fpy                     330\n",
      "month                              194\n",
      "dtype: int64\n",
      "\n",
      "DataFrame shape after all missing value handling: (10013, 25)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Missing Values after all specified handling ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nDataFrame shape after all missing value handling: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277eb9b1-5967-4b1f-a403-8be76bd0be12",
   "metadata": {},
   "source": [
    "### 7. Correct Negative ageing_sla_fpy Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3dfddbb-1487-4336-9878-c08a860c57bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Correcting Negative 'ageing_sla_fpy' Values ---\n",
      "  - Converted 75 negative values in 'ageing_sla_fpy' to 0.\n",
      "\n",
      "Min 'ageing_sla_fpy' after correction: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Correcting Negative 'ageing_sla_fpy' Values ---\")\n",
    "\n",
    "if 'ageing_sla_fpy' in df.columns:\n",
    "    negative_count_before = (df['ageing_sla_fpy'] < 0).sum()\n",
    "    if negative_count_before > 0:\n",
    "        df['ageing_sla_fpy'] = df['ageing_sla_fpy'].apply(lambda x: max(0, x) if pd.notna(x) else x)\n",
    "        print(f\"  - Converted {negative_count_before} negative values in 'ageing_sla_fpy' to 0.\")\n",
    "    else:\n",
    "        print(\"  - No negative values found in 'ageing_sla_fpy'.\")\n",
    "else:\n",
    "    print(\"  - WARNING: 'ageing_sla_fpy' column not found. Skipping correction.\")\n",
    "\n",
    "print(f\"\\nMin 'ageing_sla_fpy' after correction: {df['ageing_sla_fpy'].min()}\") # Confirm min is now >= 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df48be-01ea-4597-90ef-407b507783d2",
   "metadata": {},
   "source": [
    "Correct Negative 'amount' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b21f21f1-e9b8-4e2e-bd1b-9ff82e27ce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Correcting Negative 'amount' Values to Positive ---\n",
      "  - Converted 60 negative 'amount' values to positive.\n",
      "\n",
      "Min 'amount' after correction: 1.67\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Correcting Negative 'amount' Values to Positive ---\")\n",
    "\n",
    "if 'amount' in df.columns:\n",
    "    negative_count_before = (df['amount'] < 0).sum()\n",
    "    if negative_count_before > 0:\n",
    "        df['amount'] = df['amount'].abs() # Convert to absolute value\n",
    "        print(f\"  - Converted {negative_count_before} negative 'amount' values to positive.\")\n",
    "    else:\n",
    "        print(\"  - No negative 'amount' values found to convert.\")\n",
    "else:\n",
    "    print(\"  - WARNING: 'amount' column not found. Skipping correction.\")\n",
    "\n",
    "print(f\"\\nMin 'amount' after correction: {df['amount'].min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a97c3522-8fe7-4b58-ae4d-8cda4edf8015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final DataFrame shape after cleaning and before saving: (10013, 25)\n",
      "\n",
      "--- Final Check for Missing Values in Cleaned Data ---\n",
      "count_of_invoice                     3\n",
      "type_of_request                      0\n",
      "request_id                           0\n",
      "created_by                           0\n",
      "created_on                           0\n",
      "branch_name                          0\n",
      "supplier_code                        0\n",
      "name                                 0\n",
      "country                              0\n",
      "currency                             0\n",
      "type_of_request                      0\n",
      "amount                              11\n",
      "task_start                           0\n",
      "actioned_date                        0\n",
      "request_received_stage               0\n",
      "request_received_date                0\n",
      "completed_date                      69\n",
      "status_of_request                    0\n",
      "pending_reason                       0\n",
      "pending_with_approver/requestor      0\n",
      "qc_status                            0\n",
      "audited_by                           0\n",
      "auditor_comments                     0\n",
      "ageing_sla_fpy                     330\n",
      "month                              194\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFinal DataFrame shape after cleaning and before saving: {df.shape}\")\n",
    "print(\"\\n--- Final Check for Missing Values in Cleaned Data ---\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7727398-493d-4d70-a764-6957d74c6d8a",
   "metadata": {},
   "source": [
    "### 8. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01c2f9dd-401e-4b40-8c11-009aafdd737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Saved Successfully!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaned Data Saved Successfully!!\")\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9af9e7-2856-4a50-9310-ea2cca26066c",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
